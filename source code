import os
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
import SimpleITK as sitk
from radiomics import featureextractor

base_folder = "/Users/name/Desktop/UCSF_data"
metadata_path = "/Users/name/Desktop/UCSF-PDGM-metadata_v5.csv"

df = pd.read_csv(metadata_path)

df['EOR_bin'] = df['EOR'].map({'GTR': 1, 'STR': 0})

df = df.dropna(subset=['EOR_bin'])

print(df[['ID', 'EOR', 'EOR_bin']].head())


def extract_radiomics_features(image_path, mask_path=None):
    try:
        if mask_path is None:
            # If no mask, create one from image (non-zero voxels)
            image = sitk.ReadImage(image_path)
            mask_array = sitk.GetArrayFromImage(image) > 0
            mask = sitk.GetImageFromArray(mask_array.astype(np.uint8))
            mask.CopyInformation(image)
        else:
            mask = sitk.ReadImage(mask_path)

        params = {'force2D': False}  # Use 3D features
        extractor = featureextractor.RadiomicsFeatureExtractor(**params)
        result = extractor.execute(image_path, mask)

        # Filter only numeric features
        features = {k: v for k, v in result.items() if isinstance(v, (int, float))}
        return features

    except Exception as e:
        print(f"Error extracting features from {image_path}: {e}")
        return None




all_features = []

modalities = ['T1c_bias', 'T2', 'FLAIR']  

for _, row in df.iterrows():
    patient_id = row['ID']
    patient_folder = os.path.join(base_folder, f"{patient_id}_nifti")
    feature_dict = {'ID': patient_id, 'EOR_bin': row['EOR_bin']}
    features_collected = False

    # Always get the mask file (assume same for all modalities)
    mask_file = os.path.join(patient_folder, f"{patient_id}_tumor_segmentation.nii.gz")

    for modality in modalities:
        image_file = os.path.join(patient_folder, f"{patient_id}_{modality}.nii.gz")
        # Extract features for this modality
        features = extract_radiomics_features(image_file, mask_file)
        if features:
            features_collected = True
            # Optionally prefix the feature names with modality
            for k, v in features.items():
                feature_dict[f"{modality}_{k}"] = v

    if features_collected:
        all_features.append(feature_dict)

features_df = pd.DataFrame(all_features)

import os
import torch
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import PowerTransformer
from sklearn.feature_selection import SelectKBest, mutual_info_classif
import numpy as np
import pandas as pd

class NoisyTabularDataset(Dataset):
    def __init__(self, X, y, augment=False):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)
        self.augment = augment

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        x, y = self.X[idx], self.y[idx]
        if self.augment:
            x = x + torch.randn_like(x) * 0.05  # small Gaussian noise
        return x, y

class SmallThreeLayerModel(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 2)
        )

    def forward(self, x):
        return self.net(x)

def advanced_feature_engineering(df):
    df_copy = df.copy()
    
    numeric_cols = df_copy.select_dtypes(include=[np.number]).columns.tolist()
    numeric_cols = [c for c in numeric_cols if c not in ['ID', 'EOR_bin']]
    categorical_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()
    
    for c in numeric_cols:
        if df_copy[c].isnull().sum() > 0:
            df_copy[f'{c}_missing'] = df_copy[c].isnull().astype(int)
            df_copy[c] = df_copy[c].fillna(df_copy[c].median())
    
    for c in categorical_cols:
        df_copy[c] = df_copy[c].fillna('missing')
    df_copy = pd.get_dummies(df_copy, columns=categorical_cols, drop_first=True)
    
    return df_copy

def train_small_model(features_df, k_best_features=10, max_epochs=30):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    df = advanced_feature_engineering(features_df)
    feature_cols = [c for c in df.columns if c not in ['ID','EOR_bin']]
    X = df[feature_cols].fillna(0).values
    y = df['EOR_bin'].values

    selector = SelectKBest(score_func=mutual_info_classif, k=min(k_best_features, X.shape[1]))
    X = selector.fit_transform(X, y)

    
    scaler = PowerTransformer(method='yeo-johnson')
    X = scaler.fit_transform(X)

    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    ensemble_predictions = []

    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):
        print(f"Fold {fold} training...")
        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]

        train_dataset = NoisyTabularDataset(X_train, y_train, augment=True)
        val_dataset = NoisyTabularDataset(X_val, y_val, augment=False)

        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=32)

        model = SmallThreeLayerModel(X.shape[1]).to(device)
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=1e-3)

        best_val_loss = float('inf')
        patience, patience_counter = 7, 0

        for epoch in range(max_epochs):
            model.train()
            for xb, yb in train_loader:
                xb, yb = xb.to(device), yb.to(device)
                optimizer.zero_grad()
                out = model(xb)
                loss = criterion(out, yb)
                loss.backward()
                optimizer.step()

            model.eval()
            val_loss = 0
            with torch.no_grad():
                for xb, yb in val_loader:
                    xb, yb = xb.to(device), yb.to(device)
                    out = model(xb)
                    val_loss += criterion(out, yb).item() * xb.size(0)
            val_loss /= len(val_loader.dataset)

            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                torch.save(model.state_dict(), f'best_model_fold{fold}.pth')
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    break

        model.load_state_dict(torch.load(f'best_model_fold{fold}.pth'))
        model.eval()
        with torch.no_grad():
            X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)
            outputs = model(X_val_tensor)
            probs = torch.softmax(outputs, dim=1).cpu().numpy()
            ensemble_predictions.append((probs, y_val))

    all_preds, all_labels = [], []
    for preds, labels in ensemble_predictions:
        all_preds.extend(np.argmax(preds, axis=1))
        all_labels.extend(labels)
    acc = np.mean(np.array(all_preds) == np.array(all_labels))
    print(f"Ensemble Accuracy (reduced model): {acc:.4f}")
    return ensemble_predictions


ensemble_preds = train_ensemble(df)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

def evaluate_ensemble_metrics(ensemble_preds):
    all_preds = []
    all_labels = []
    all_probs = []

    for probs, labels in ensemble_preds:
        preds = np.argmax(probs, axis=1)
        all_preds.extend(preds)
        all_labels.extend(labels)
        # Store probability for positive class (assuming class 1 is positive)
        all_probs.extend(probs[:, 1])

    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    all_probs = np.array(all_probs)

    acc = accuracy_score(all_labels, all_preds)
    prec = precision_score(all_labels, all_preds)
    rec = recall_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds)
    try:
        roc_auc = roc_auc_score(all_labels, all_probs)
    except ValueError:
        roc_auc = float('nan')  # In case only one class present in y_true

    print(f"Accuracy: {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall: {rec:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"ROC AUC: {roc_auc:.4f}")

    return {
        "accuracy": acc,
        "precision": prec,
        "recall": rec,
        "f1_score": f1,
        "roc_auc": roc_auc
    }

import pandas as pd
import numpy as np
from sklearn.preprocessing import PowerTransformer
from sklearn.feature_selection import SelectKBest, mutual_info_classif
from sklearn.model_selection import StratifiedKFold


def check_patient_duplicates(df):
    duplicate_ids = df['ID'][df['ID'].duplicated()]
    if len(duplicate_ids) > 0:
        print("WARNING: Duplicate patient IDs found:", duplicate_ids.tolist())
    else:
        print("No duplicate patient IDs detected.")

def check_feature_label_corr(df):
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    numeric_cols = [c for c in numeric_cols if c not in ['ID', 'EOR_bin']]
    
    correlations = df[numeric_cols + ['EOR_bin']].corr()['EOR_bin'].abs().sort_values(ascending=False)
    high_corr = correlations[correlations > 0.9]  # threshold for suspiciously high correlation
    if len(high_corr) > 1:  # 'EOR_bin' itself will be 1.0
        print("Features highly correlated with label (possible leakage):")
        print(high_corr.drop('EOR_bin'))
    else:
        print("No features with suspiciously high correlation to the label.")

def check_preprocessing_leakage(df, k_best_features=40):
    feature_cols = [c for c in df.columns if c not in ['ID', 'EOR_bin']]
    X = df[feature_cols].fillna(0).values
    y = df['EOR_bin'].values
    
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):
        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]
        
        # Feature selection on training only
        selector = SelectKBest(score_func=mutual_info_classif, k=min(k_best_features, X_train.shape[1]))
        X_train_selected = selector.fit_transform(X_train, y_train)
        X_val_selected = selector.transform(X_val)
        
        # Scaling on training only
        scaler = PowerTransformer(method='yeo-johnson')
        X_train_scaled = scaler.fit_transform(X_train_selected)
        X_val_scaled = scaler.transform(X_val_selected)
        
        if np.isnan(X_val_scaled).any():
            print(f"Fold {fold}: NaNs detected after scaling (possible leakage or preprocessing issue)")
        else:
            print(f"Fold {fold}: Preprocessing applied correctly, no leakage detected.")

def run_leakage_checks(df):
    print("\n--- Checking patient-level duplicates ---")
    check_patient_duplicates(df)
    
    print("\n--- Checking feature-label correlations ---")
    check_feature_label_corr(df)
    
    print("\n--- Checking preprocessing leakage during CV ---")
    check_preprocessing_leakage(df)

run_leakage_checks(features_df)


import numpy as np

def permutation_test(features_df, n_permutations=5):
    from copy import deepcopy
    from sklearn.metrics import accuracy_score
    
    # Store original labels
    y_orig = features_df['EOR_bin'].values
    X_orig = features_df.drop(columns=['ID','EOR_bin'])
    
    print("\n--- Running Permutation Test ---")
    
    for i in range(n_permutations):
        # Shuffle labels
        y_shuffled = np.random.permutation(y_orig)
        df_shuffled = deepcopy(features_df)
        df_shuffled['EOR_bin'] = y_shuffled
        
        # Train ensemble on shuffled labels
        ensemble_preds = train_ensemble(df_shuffled)
        
        # Compute accuracy on all validation folds
        all_preds, all_labels = [], []
        for preds, labels in ensemble_preds:
            all_preds.extend(np.argmax(preds, axis=1))
            all_labels.extend(labels)
        acc = np.mean(np.array(all_preds) == np.array(all_labels))
        print(f"Permutation {i+1}: Accuracy = {acc:.4f}")

permutation_test(features_df, n_permutations=5)


#Alt

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import PowerTransformer
from sklearn.feature_selection import SelectKBest, mutual_info_classif
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

class NoisyTabularDataset(Dataset):
    def __init__(self, X, y, augment=False):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)
        self.augment = augment
    def __len__(self):
        return len(self.y)
    def __getitem__(self, idx):
        x, y = self.X[idx], self.y[idx]
        if self.augment:
            x = x + torch.randn_like(x) * 0.05
        return x, y

class SmallThreeLayerModel(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 2)
        )
    def forward(self, x):
        return self.net(x)

def advanced_feature_engineering(df):
    df_copy = df.copy()
    numeric_cols = df_copy.select_dtypes(include=[np.number]).columns.tolist()
    numeric_cols = [c for c in numeric_cols if c not in ['ID','EOR_bin']]
    categorical_cols = df_copy.select_dtypes(include=['object','category']).columns.tolist()
    
    for c in numeric_cols:
        if df_copy[c].isnull().sum() > 0:
            df_copy[f'{c}_missing'] = df_copy[c].isnull().astype(int)
            df_copy[c] = df_copy[c].fillna(df_copy[c].median())
    for c in categorical_cols:
        df_copy[c] = df_copy[c].fillna('missing')
    df_copy = pd.get_dummies(df_copy, columns=categorical_cols, drop_first=True)
    return df_copy

def train_small_model(features_df, k_best_features=20, max_epochs=30):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    df = advanced_feature_engineering(features_df)
    feature_cols = [c for c in df.columns if c not in ['ID','EOR_bin']]
    X = df[feature_cols].fillna(0).values
    y = df['EOR_bin'].values

    selector = SelectKBest(score_func=mutual_info_classif, k=min(k_best_features, X.shape[1]))
    X_selected = selector.fit_transform(X, y)
    selected_features = [feature_cols[i] for i in selector.get_support(indices=True)]
    print("Top selected features (MI):", selected_features)

    scaler = PowerTransformer(method='yeo-johnson')
    X_scaled = scaler.fit_transform(X_selected)
    
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    ensemble_predictions = []
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(X_scaled, y), 1):
        print(f"Fold {fold} training...")
        X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]
        
        train_dataset = NoisyTabularDataset(X_train, y_train, augment=True)
        val_dataset = NoisyTabularDataset(X_val, y_val, augment=False)
        
        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=32)
        
        model = SmallThreeLayerModel(X_scaled.shape[1]).to(device)
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=1e-3)
        
        best_val_loss = float('inf')
        patience, patience_counter = 7, 0
        
        for epoch in range(max_epochs):
            model.train()
            for xb, yb in train_loader:
                xb, yb = xb.to(device), yb.to(device)
                optimizer.zero_grad()
                out = model(xb)
                loss = criterion(out, yb)
                loss.backward()
                optimizer.step()
            model.eval()
            val_loss = 0
            with torch.no_grad():
                for xb, yb in val_loader:
                    xb, yb = xb.to(device), yb.to(device)
                    out = model(xb)
                    val_loss += criterion(out, yb).item() * xb.size(0)
            val_loss /= len(val_loader.dataset)
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                torch.save(model.state_dict(), f'best_model_fold{fold}.pth')
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    break
        
        model.load_state_dict(torch.load(f'best_model_fold{fold}.pth'))
        model.eval()
        with torch.no_grad():
            X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)
            outputs = model(X_val_tensor)
            probs = torch.softmax(outputs, dim=1).cpu().numpy()
            ensemble_predictions.append((probs, y_val))
    
    all_preds, all_labels = [], []
    for preds, labels in ensemble_predictions:
        all_preds.extend(np.argmax(preds, axis=1))
        all_labels.extend(labels)
    acc = np.mean(np.array(all_preds) == np.array(all_labels))
    print(f"Ensemble Accuracy: {acc:.4f}")
    
    lr = LogisticRegression(max_iter=1000)
    lr.fit(X_scaled, y)
    coefs = lr.coef_[0]
    
    feature_effects = []
    for feat, coef in zip(selected_features, coefs):
        direction = "GTR↑" if coef>0 else "STR↑"
        feature_effects.append((feat, coef, direction))
    
    return ensemble_predictions, feature_effects

def evaluate_ensemble_metrics(ensemble_preds):
    all_preds, all_labels, all_probs = [], [], []
    for probs, labels in ensemble_preds:
        preds = np.argmax(probs, axis=1)
        all_preds.extend(preds)
        all_labels.extend(labels)
        all_probs.extend(probs[:,1])  # probability of GTR
    
    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    all_probs = np.array(all_probs)
    
    print("Accuracy:", accuracy_score(all_labels, all_preds))
    print("Precision:", precision_score(all_labels, all_preds))
    print("Recall:", recall_score(all_labels, all_preds))
    print("F1 Score:", f1_score(all_labels, all_preds))
    try:
        print("ROC AUC:", roc_auc_score(all_labels, all_probs))
    except ValueError:
        print("ROC AUC: Not available (single class present)")

ensemble_preds, feature_effects = train_small_model(features_df)
evaluate_ensemble_metrics(ensemble_preds)

print("\nTop features and direction of effect (GTR↑ means higher value favors GTR):")
for feat, coef, direction in feature_effects:
    print(f"{feat}: coef={coef:.3f} → {direction}")


from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

def evaluate_ensemble_metrics(ensemble_preds):
    all_preds = []
    all_labels = []
    all_probs = []

    for probs, labels in ensemble_preds:
        preds = np.argmax(probs, axis=1)
        all_preds.extend(preds)
        all_labels.extend(labels)
        # Store probability for positive class (assuming class 1 is positive)
        all_probs.extend(probs[:, 1])

    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    all_probs = np.array(all_probs)

    acc = accuracy_score(all_labels, all_preds)
    prec = precision_score(all_labels, all_preds)
    rec = recall_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds)
    try:
        roc_auc = roc_auc_score(all_labels, all_probs)
    except ValueError:
        roc_auc = float('nan')  

    print(f"Accuracy: {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall: {rec:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"ROC AUC: {roc_auc:.4f}")

    return {
        "accuracy": acc,
        "precision": prec,
        "recall": rec,
        "f1_score": f1,
        "roc_auc": roc_auc
    }




